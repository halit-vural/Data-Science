{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12500,"databundleVersionId":1375107,"sourceType":"competition"},{"sourceId":19018,"databundleVersionId":2703900,"sourceType":"competition"},{"sourceId":27935,"databundleVersionId":3445671,"sourceType":"competition"},{"sourceId":2798066,"sourceType":"datasetVersion","datasetId":1709138}],"dockerImageVersionId":30146,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\n## [Jigsaw Rate Severity of Toxic Comments][1]\n---\nreference notebooks\n1. [☣️ Jigsaw - Incredibly Simple Naive Bayes [0.768]][2]\n2. [AutoNLP for toxic ratings ;)][3]\n\n\n[1]: https://www.kaggle.com/c/jigsaw-toxic-severity-rating/overview\n[2]: https://www.kaggle.com/julian3833/jigsaw-incredibly-simple-naive-bayes-0-768\n[3]: https://www.kaggle.com/abhishek/autonlp-for-toxic-ratings","metadata":{}},{"cell_type":"markdown","source":"# 0. Settings","metadata":{}},{"cell_type":"code","source":"# Import dependencies libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os\nimport pathlib\nimport gc\nimport sys\nimport math \nimport time \nimport tqdm \nfrom tqdm import tqdm \nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold \nfrom sklearn.model_selection import StratifiedKFold \n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers.experimental import preprocessing\n\nimport transformers \nimport datasets ","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:10:20.475877Z","iopub.execute_input":"2025-02-20T13:10:20.476107Z","iopub.status.idle":"2025-02-20T13:10:28.950974Z","shell.execute_reply.started":"2025-02-20T13:10:20.476039Z","shell.execute_reply":"2025-02-20T13:10:28.950432Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# global config set up\nconfig = {\n    'nfolds': 10,\n    'learning_rate': 1e-4,\n    'num_epochs': 3,\n    'batch_size': 8,\n}\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \nglobal_seed = 42\nseed_all(global_seed)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:10:40.522999Z","iopub.execute_input":"2025-02-20T13:10:40.523631Z","iopub.status.idle":"2025-02-20T13:10:40.528688Z","shell.execute_reply.started":"2025-02-20T13:10:40.523593Z","shell.execute_reply":"2025-02-20T13:10:40.527885Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# data\nDATA_PATH = '../input/jigsaw-toxic-comment-classification-challenge/train.csv'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:10:46.902576Z","iopub.execute_input":"2025-02-20T13:10:46.903077Z","iopub.status.idle":"2025-02-20T13:10:46.906578Z","shell.execute_reply.started":"2025-02-20T13:10:46.903042Z","shell.execute_reply":"2025-02-20T13:10:46.905682Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 1. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"### 1. Create train data\n\nFor training data, I used [Toxic Comment Classification Challenge][1] dataset.\n\n[1]: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data\n\nI turn it into a binary toxic/ no-toxic classification","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(DATA_PATH)\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0 ).astype(int)\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:11:24.118277Z","iopub.execute_input":"2025-02-20T13:11:24.118956Z","iopub.status.idle":"2025-02-20T13:11:25.001355Z","shell.execute_reply.started":"2025-02-20T13:11:24.118925Z","shell.execute_reply":"2025-02-20T13:11:25.000618Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                     text  y\n108725  July 2009 \\n\\nThe recent edit you made to soju...  0\n102598  \"\\n OK. Then don't )Although I resent your sug...  0\n149377  An editor should be careful and specific about...  0\n11262   (Note: I have posted a message on WP:AN regard...  0\n32217                         Kurt Wallander. 194.81.33.9  0\n2540    This should be noted as it makes it a detrimen...  0\n96947   I'll be back!! \\n\\nFrom now on SJP, or shithea...  1\n139092  what don't you understand about fair use? does...  0\n105051  Samanda \\n\\nWhat is your source on the new sin...  0\n95556   Rot In Hell \\n\\nRot in hell asshole.\\nYou dirt...  1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>108725</th>\n      <td>July 2009 \\n\\nThe recent edit you made to soju...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>102598</th>\n      <td>\"\\n OK. Then don't )Although I resent your sug...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149377</th>\n      <td>An editor should be careful and specific about...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11262</th>\n      <td>(Note: I have posted a message on WP:AN regard...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32217</th>\n      <td>Kurt Wallander. 194.81.33.9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2540</th>\n      <td>This should be noted as it makes it a detrimen...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96947</th>\n      <td>I'll be back!! \\n\\nFrom now on SJP, or shithea...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>139092</th>\n      <td>what don't you understand about fair use? does...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>105051</th>\n      <td>Samanda \\n\\nWhat is your source on the new sin...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>95556</th>\n      <td>Rot In Hell \\n\\nRot in hell asshole.\\nYou dirt...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"### 1.2 Undersampling\n\nThe dataset is very unbalanced. Here we undersample the majority class. Other strategies might work better.","metadata":{}},{"cell_type":"code","source":"df['y'].value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:12:10.191956Z","iopub.execute_input":"2025-02-20T13:12:10.192701Z","iopub.status.idle":"2025-02-20T13:12:10.199848Z","shell.execute_reply.started":"2025-02-20T13:12:10.192663Z","shell.execute_reply":"2025-02-20T13:12:10.199170Z"},"trusted":true},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0    0.898321\n1    0.101679\nName: y, dtype: float64"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df['y'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:12:44.322745Z","iopub.execute_input":"2025-02-20T13:12:44.323431Z","iopub.status.idle":"2025-02-20T13:12:44.329948Z","shell.execute_reply.started":"2025-02-20T13:12:44.323396Z","shell.execute_reply":"2025-02-20T13:12:44.329247Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0    143346\n1     16225\nName: y, dtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"min_len = (df['y'] == 1).sum()\ndf_y0_undersample = df[df['y'] == 0].sample(n=min_len, random_state=global_seed)\ntrain_df = pd.concat([df[df['y'] == 1], df_y0_undersample]).reset_index(drop=True)\ntrain_df['y'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:13:24.579523Z","iopub.execute_input":"2025-02-20T13:13:24.580298Z","iopub.status.idle":"2025-02-20T13:13:24.608826Z","shell.execute_reply.started":"2025-02-20T13:13:24.580262Z","shell.execute_reply":"2025-02-20T13:13:24.608150Z"},"trusted":true},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"1    16225\n0    16225\nName: y, dtype: int64"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"train_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:14:00.857969Z","iopub.execute_input":"2025-02-20T13:14:00.858487Z","iopub.status.idle":"2025-02-20T13:14:00.867408Z","shell.execute_reply.started":"2025-02-20T13:14:00.858450Z","shell.execute_reply":"2025-02-20T13:14:00.866648Z"},"trusted":true},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                                    text  y\n31654  }}\\n{{WikiProject Energy| class = Start| impor...  0\n22024  Blocking, gagging, and so forth \\n\\nDoes it no...  0\n19337  Personally I don't care about whatever has gon...  0\n11274                   MUSLIM SCUM go die soon will you  1\n4749   \"\\n\\nI didn't call you a \"\"biased backward yan...  1\n20888  You called? \\n\\nWhat's up Shiitthead? I have 2...  0\n26383  Propaganda \\n\\nThis article is pure propaganda...  0\n19156  \"\\nFeel free to notify me when you submit any ...  0\n25590  Please refrain from adding nonsense, such as e...  0\n21270  \"\\n\\nAccording to this comment I am bashing La...  0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>31654</th>\n      <td>}}\\n{{WikiProject Energy| class = Start| impor...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22024</th>\n      <td>Blocking, gagging, and so forth \\n\\nDoes it no...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19337</th>\n      <td>Personally I don't care about whatever has gon...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11274</th>\n      <td>MUSLIM SCUM go die soon will you</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4749</th>\n      <td>\"\\n\\nI didn't call you a \"\"biased backward yan...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20888</th>\n      <td>You called? \\n\\nWhat's up Shiitthead? I have 2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26383</th>\n      <td>Propaganda \\n\\nThis article is pure propaganda...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19156</th>\n      <td>\"\\nFeel free to notify me when you submit any ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25590</th>\n      <td>Please refrain from adding nonsense, such as e...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21270</th>\n      <td>\"\\n\\nAccording to this comment I am bashing La...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"### 1.3 k-fold","metadata":{}},{"cell_type":"code","source":"n_folds = 10\n\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=global_seed)\nfor nfold, (train_index, val_index) in enumerate(skf.split(X=train_df.index,\n                                                           y=train_df.y)):\n    train_df.loc[val_index, 'fold'] = nfold\nprint(train_df.groupby(['fold', train_df.y]).size())","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:17:39.514615Z","iopub.execute_input":"2025-02-20T13:17:39.515328Z","iopub.status.idle":"2025-02-20T13:17:39.536333Z","shell.execute_reply.started":"2025-02-20T13:17:39.515291Z","shell.execute_reply":"2025-02-20T13:17:39.535681Z"},"trusted":true},"outputs":[{"name":"stdout","text":"fold  y\n0.0   0    1622\n      1    1623\n1.0   0    1622\n      1    1623\n2.0   0    1622\n      1    1623\n3.0   0    1622\n      1    1623\n4.0   0    1622\n      1    1623\n5.0   0    1623\n      1    1622\n6.0   0    1623\n      1    1622\n7.0   0    1623\n      1    1622\n8.0   0    1623\n      1    1622\n9.0   0    1623\n      1    1622\ndtype: int64\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"p_fold = 0\np_train = train_df.query(f'fold != {p_fold}').reset_index(drop=True)\np_valid = train_df.query(f'fold == {p_fold}').reset_index(drop=True)\n\nprint(len(p_train))\nprint(len(p_valid))\n\np_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:16:30.766699Z","iopub.execute_input":"2025-02-20T13:16:30.767454Z","iopub.status.idle":"2025-02-20T13:16:30.790848Z","shell.execute_reply.started":"2025-02-20T13:16:30.767417Z","shell.execute_reply":"2025-02-20T13:16:30.790134Z"},"trusted":true},"outputs":[{"name":"stdout","text":"29205\n3245\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"                                                text  y  fold\n0       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK  1   2.0\n1  Hey... what is it..\\n@ | talk .\\nWhat is it......  1   1.0\n2  Bye! \\n\\nDon't look, come or think of comming ...  1   1.0\n3           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!  1   8.0\n4  I'm Sorry \\n\\nI'm sorry I screwed around with ...  1   6.0\n5  GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...  1   1.0\n6  Stupid peace of shit stop deleting my stuff as...  1   8.0\n7  =Tony Sidaway is obviously a fistfuckee. He lo...  1   1.0\n8  Why can't you believe how fat Artie is? Did yo...  1   6.0\n9  All of my edits are good.  Cunts like you who ...  1   6.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>y</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n      <td>1</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm Sorry \\n\\nI'm sorry I screwed around with ...</td>\n      <td>1</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Stupid peace of shit stop deleting my stuff as...</td>\n      <td>1</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Why can't you believe how fat Artie is? Did yo...</td>\n      <td>1</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>All of my edits are good.  Cunts like you who ...</td>\n      <td>1</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"# 2. DataSet","metadata":{}},{"cell_type":"code","source":"checkpoint = \"bert-large-uncased\"\ntokenizer = transformers.AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:21:11.225831Z","iopub.execute_input":"2025-02-20T13:21:11.226088Z","iopub.status.idle":"2025-02-20T13:21:11.992734Z","shell.execute_reply.started":"2025-02-20T13:21:11.226057Z","shell.execute_reply":"2025-02-20T13:21:11.992152Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"checkpoint = \"bert-base-uncased\"\ntokenizer = transformers.BertTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:21:30.638060Z","iopub.execute_input":"2025-02-20T13:21:30.638325Z","iopub.status.idle":"2025-02-20T13:21:30.643218Z","shell.execute_reply.started":"2025-02-20T13:21:30.638296Z","shell.execute_reply":"2025-02-20T13:21:30.642558Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizerFast(name_or_path='bert-large-uncased', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_ds = datasets.Dataset.from_pandas(p_train)\nvalid_ds = datasets.Dataset.from_pandas(p_valid)\n\nprint(train_ds)\nprint(valid_ds)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:22:05.034069Z","iopub.execute_input":"2025-02-20T13:22:05.034630Z","iopub.status.idle":"2025-02-20T13:22:05.091387Z","shell.execute_reply.started":"2025-02-20T13:22:05.034586Z","shell.execute_reply":"2025-02-20T13:22:05.090674Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text', 'y', 'fold'],\n    num_rows: 29205\n})\nDataset({\n    features: ['text', 'y', 'fold'],\n    num_rows: 3245\n})\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(example[\"text\"], truncation=True)\n\ntokenized_train_ds = train_ds.map(tokenize_function, batched=True)\ntokenized_valid_ds = valid_ds.map(tokenize_function, batched=True)\n\nprint(tokenized_train_ds)\nprint(tokenized_valid_ds)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:22:37.781536Z","iopub.execute_input":"2025-02-20T13:22:37.782103Z","iopub.status.idle":"2025-02-20T13:22:42.121994Z","shell.execute_reply.started":"2025-02-20T13:22:37.782071Z","shell.execute_reply":"2025-02-20T13:22:42.121160Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed0170b30528448686b2f7c80b98bb50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d50fc1f8934053a2cd7026e5ebde62"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['attention_mask', 'fold', 'input_ids', 'text', 'token_type_ids', 'y'],\n    num_rows: 29205\n})\nDataset({\n    features: ['attention_mask', 'fold', 'input_ids', 'text', 'token_type_ids', 'y'],\n    num_rows: 3245\n})\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n\ntf_train_ds = tokenized_train_ds.to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    label_cols=[\"y\"],\n    shuffle=True,\n    collate_fn=data_collator,\n    batch_size=config['batch_size'],\n)\n\ntf_valid_ds = tokenized_valid_ds.to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    label_cols=[\"y\"],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=config['batch_size'],\n)\n\nprint(len(tf_train_ds))\nprint(len(tf_valid_ds))","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:24:23.080530Z","iopub.execute_input":"2025-02-20T13:24:23.081212Z","iopub.status.idle":"2025-02-20T13:24:28.752903Z","shell.execute_reply.started":"2025-02-20T13:24:23.081180Z","shell.execute_reply":"2025-02-20T13:24:28.752144Z"},"trusted":true},"outputs":[{"name":"stdout","text":"3650\n406\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# 3. Model Training","metadata":{}},{"cell_type":"code","source":"from transformers import TFAutoModelForSequenceClassification\n\nmodel = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:25:07.546071Z","iopub.execute_input":"2025-02-20T13:25:07.546666Z","iopub.status.idle":"2025-02-20T13:25:33.045885Z","shell.execute_reply.started":"2025-02-20T13:25:07.546624Z","shell.execute_reply":"2025-02-20T13:25:33.045302Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.47G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb7793e8c5d4751b74187d29c933482"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n\nSome layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"num_epochs = 2\nnum_train_steps = len(tf_train_ds) * num_epochs\n\nlr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n    initial_learning_rate=5e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:32:25.340658Z","iopub.execute_input":"2025-02-20T13:32:25.341192Z","iopub.status.idle":"2025-02-20T13:32:25.375403Z","shell.execute_reply.started":"2025-02-20T13:32:25.341157Z","shell.execute_reply":"2025-02-20T13:32:25.374709Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Model: \"tf_bert_for_sequence_classification\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbert (TFBertMainLayer)       multiple                  335141888 \n_________________________________________________________________\ndropout_73 (Dropout)         multiple                  0         \n_________________________________________________________________\nclassifier (Dense)           multiple                  2050      \n=================================================================\nTotal params: 335,143,938\nTrainable params: 335,143,938\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:36:29.717961Z","iopub.execute_input":"2025-02-20T13:36:29.718743Z","iopub.status.idle":"2025-02-20T13:36:29.723304Z","shell.execute_reply.started":"2025-02-20T13:36:29.718702Z","shell.execute_reply":"2025-02-20T13:36:29.722481Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  1\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"If the output is Num GPUs Available: 1 (or more), TensorFlow detects the GPU.\n\nIf TensorFlow detects the GPU but still uses the CPU, you can explicitly force it to use the GPU.","metadata":{}},{"cell_type":"code","source":"with tf.device('/GPU:0'):\n    fit_history = model.fit(tf_train_ds,\n                        epochs=num_epochs,\n                        validation_data=tf_valid_ds,\n                        verbose=1)","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:38:22.821013Z","iopub.execute_input":"2025-02-20T13:38:22.821603Z","iopub.status.idle":"2025-02-20T13:38:33.357805Z","shell.execute_reply.started":"2025-02-20T13:38:22.821564Z","shell.execute_reply":"2025-02-20T13:38:33.356776Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/2044730571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_valid_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         verbose=1)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node tf_bert_for_sequence_classification/bert/encoder/layer_._21/attention/self/dropout_64/dropout/GreaterEqual (defined at opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:272) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_45425]\n\nFunction call stack:\ntrain_function\n"],"ename":"ResourceExhaustedError","evalue":" failed to allocate memory\n\t [[node tf_bert_for_sequence_classification/bert/encoder/layer_._21/attention/self/dropout_64/dropout/GreaterEqual (defined at opt/conda/lib/python3.7/site-packages/transformers/models/bert/modeling_tf_bert.py:272) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_45425]\n\nFunction call stack:\ntrain_function\n","output_type":"error"}],"execution_count":34},{"cell_type":"markdown","source":"# 4. Prediction & Submit","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ntest_ds = datasets.Dataset.from_pandas(test_df)\ntokenized_test_ds = test_ds.map(tokenize_function, batched=True)\ntf_test_ds = tokenized_test_ds.to_tf_dataset(\n    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n    shuffle=False,\n    collate_fn=data_collator,\n    batch_size=config['batch_size'],\n)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T02:57:05.160662Z","iopub.execute_input":"2024-12-23T02:57:05.160944Z","iopub.status.idle":"2024-12-23T02:57:16.995707Z","shell.execute_reply.started":"2024-12-23T02:57:05.160914Z","shell.execute_reply":"2024-12-23T02:57:16.995143Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"raw_result = model.predict(tf_test_ds)\nresult = tf.sigmoid(raw_result.logits)\n\ntest_df['score'] = result.numpy()[:, 0]\nsubmission_df = test_df[['comment_id', 'score']]\n\n# submission_df.to_csv(\"submission.csv\", index=False) \nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2024-12-23T02:57:56.828008Z","iopub.execute_input":"2024-12-23T02:57:56.828266Z","iopub.status.idle":"2024-12-23T02:59:40.941255Z","shell.execute_reply.started":"2024-12-23T02:57:56.828237Z","shell.execute_reply":"2024-12-23T02:59:40.940561Z"},"trusted":true},"outputs":[],"execution_count":null}]}